2018-06-09 02:12:47,030 INFO  [main] datanode.DataNode (LogAdapter.java:info(51)) - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = slave1/172.18.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.1
STARTUP_MSG:   classpath = /home/hadoop/hadoop_latest/etc/hadoop:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsch-0.1.54.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/avro-1.7.7.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/hadoop-auth-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/hadoop-annotations-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-common-2.9.1-tests.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-common-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-nfs-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1-tests.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-2.9.1-tests.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1-tests.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1-tests.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/fst-2.50.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-router-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-client-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-registry-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-common-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-common-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-api-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.1.jar:/home/hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e30710aea4e6e55e69372929106cf119af06fd0e; compiled by 'root' on 2018-04-16T09:33Z
STARTUP_MSG:   java = 1.8.0_171
************************************************************/
2018-06-09 02:12:47,037 INFO  [main] datanode.DataNode (LogAdapter.java:info(51)) - registered UNIX signal handlers for [TERM, HUP, INT]
2018-06-09 02:12:47,309 INFO  [main] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(122)) - Scheduling a check for [DISK]file:/home/hadoop/hadoopdata/hdfs/datanode/
2018-06-09 02:12:47,357 WARN  [main] impl.MetricsConfig (MetricsConfig.java:loadFirst(128)) - Cannot locate configuration: tried hadoop-metrics2-datanode.properties,hadoop-metrics2.properties
2018-06-09 02:12:47,393 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2018-06-09 02:12:47,394 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - DataNode metrics system started
2018-06-09 02:12:47,398 INFO  [main] common.Util (Util.java:isDiskStatsEnabled(111)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2018-06-09 02:12:47,400 INFO  [main] datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2018-06-09 02:12:47,402 INFO  [main] datanode.DataNode (DataNode.java:<init>(494)) - Configured hostname is slave1
2018-06-09 02:12:47,402 INFO  [main] common.Util (Util.java:isDiskStatsEnabled(111)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2018-06-09 02:12:47,402 WARN  [main] conf.Configuration (Configuration.java:getTimeDurationHelper(1701)) - No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2018-06-09 02:12:47,405 INFO  [main] datanode.DataNode (DataNode.java:startDataNode(1353)) - Starting DataNode with maxLockedMemory = 0
2018-06-09 02:12:47,418 INFO  [main] datanode.DataNode (DataNode.java:initDataXceiver(1124)) - Opened streaming server at /0.0.0.0:50010
2018-06-09 02:12:47,419 INFO  [main] datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2018-06-09 02:12:47,419 INFO  [main] datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2018-06-09 02:12:47,473 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-06-09 02:12:47,480 INFO  [main] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-06-09 02:12:47,490 INFO  [main] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2018-06-09 02:12:47,494 INFO  [main] http.HttpServer2 (HttpServer2.java:addGlobalFilter(805)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-06-09 02:12:47,496 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(780)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2018-06-09 02:12:47,496 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(788)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-06-09 02:12:47,496 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(788)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-06-09 02:12:47,507 INFO  [main] http.HttpServer2 (HttpServer2.java:bindListener(1003)) - Jetty bound to port 46393
2018-06-09 02:12:47,507 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2018-06-09 02:12:47,637 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:46393
2018-06-09 02:12:47,754 INFO  [main] web.DatanodeHttpServer (DatanodeHttpServer.java:start(249)) - Listening HTTP traffic on /0.0.0.0:50075
2018-06-09 02:12:47,758 INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@31d0e481] util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2018-06-09 02:12:47,775 INFO  [main] datanode.DataNode (DataNode.java:startDataNode(1380)) - dnUserName = hadoop
2018-06-09 02:12:47,775 INFO  [main] datanode.DataNode (DataNode.java:startDataNode(1381)) - supergroup = supergroup
2018-06-09 02:12:47,805 INFO  [main] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-06-09 02:12:47,816 INFO  [Socket Reader #1 for port 50020] ipc.Server (Server.java:run(1069)) - Starting Socket Reader #1 for port 50020
2018-06-09 02:12:47,943 INFO  [main] datanode.DataNode (DataNode.java:initIpcServer(1037)) - Opened IPC server at /0.0.0.0:50020
2018-06-09 02:12:47,951 INFO  [main] datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2018-06-09 02:12:47,959 INFO  [main] datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(198)) - Starting BPOfferServices for nameservices: <default>
2018-06-09 02:12:47,966 INFO  [Thread-19] datanode.DataNode (BPServiceActor.java:run(809)) - Block pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.3:9000 starting to offer service
2018-06-09 02:12:47,970 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1309)) - IPC Server Responder: starting
2018-06-09 02:12:47,970 INFO  [IPC Server listener on 50020] ipc.Server (Server.java:run(1148)) - IPC Server listener on 50020: starting
2018-06-09 02:12:48,100 INFO  [Thread-19] datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(376)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to master/172.18.0.3:9000
2018-06-09 02:12:48,101 INFO  [Thread-19] common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(355)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2018-06-09 02:12:48,105 INFO  [Thread-19] common.Storage (Storage.java:tryLock(792)) - Lock on /home/hadoop/hadoopdata/hdfs/datanode/in_use.lock acquired by nodename 27426@slave1
2018-06-09 02:12:48,105 INFO  [Thread-19] common.Storage (DataStorage.java:loadStorageDirectory(280)) - Storage directory /home/hadoop/hadoopdata/hdfs/datanode is not formatted for namespace 1825193457. Formatting...
2018-06-09 02:12:48,106 INFO  [Thread-19] common.Storage (DataStorage.java:createStorageID(158)) - Generated new storageID DS-b3ff0b9c-a1d0-4c0d-8637-0c4e8c6e9b7d for directory /home/hadoop/hadoopdata/hdfs/datanode
2018-06-09 02:12:48,123 INFO  [Thread-19] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(249)) - Analyzing storage directories for bpid BP-1513679204-172.18.0.3-1528503999525
2018-06-09 02:12:48,123 INFO  [Thread-19] common.Storage (Storage.java:lock(751)) - Locking is disabled for /home/hadoop/hadoopdata/hdfs/datanode/current/BP-1513679204-172.18.0.3-1528503999525
2018-06-09 02:12:48,123 INFO  [Thread-19] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(164)) - Block pool storage directory /home/hadoop/hadoopdata/hdfs/datanode/current/BP-1513679204-172.18.0.3-1528503999525 is not formatted for BP-1513679204-172.18.0.3-1528503999525. Formatting ...
2018-06-09 02:12:48,124 INFO  [Thread-19] common.Storage (BlockPoolSliceStorage.java:format(277)) - Formatting block pool BP-1513679204-172.18.0.3-1528503999525 directory /home/hadoop/hadoopdata/hdfs/datanode/current/BP-1513679204-172.18.0.3-1528503999525/current
2018-06-09 02:12:48,125 INFO  [Thread-19] datanode.DataNode (DataNode.java:initStorage(1652)) - Setting up storage: nsid=1825193457;bpid=BP-1513679204-172.18.0.3-1528503999525;lv=-57;nsInfo=lv=-63;cid=CID-a22712bb-353f-4d34-8c7b-3757042d6470;nsid=1825193457;c=1528503999525;bpid=BP-1513679204-172.18.0.3-1528503999525;dnuuid=null
2018-06-09 02:12:48,126 INFO  [Thread-19] datanode.DataNode (DataNode.java:checkDatanodeUuid(1480)) - Generated and persisted new Datanode UUID cb2929c8-f03f-4732-973a-dcb27b4b7fed
2018-06-09 02:12:48,153 INFO  [Thread-19] impl.FsDatasetImpl (FsVolumeList.java:addVolume(300)) - Added new volume: DS-b3ff0b9c-a1d0-4c0d-8637-0c4e8c6e9b7d
2018-06-09 02:12:48,153 INFO  [Thread-19] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(461)) - Added volume - /home/hadoop/hadoopdata/hdfs/datanode/current, StorageType: DISK
2018-06-09 02:12:48,155 INFO  [Thread-19] impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2363)) - Registered FSDatasetState MBean
2018-06-09 02:12:48,159 INFO  [Thread-19] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(122)) - Scheduling a check for /home/hadoop/hadoopdata/hdfs/datanode/current
2018-06-09 02:12:48,163 INFO  [Thread-19] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(210)) - Scheduled health check for volume /home/hadoop/hadoopdata/hdfs/datanode/current
2018-06-09 02:12:48,164 INFO  [Thread-19] impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2861)) - Adding block pool BP-1513679204-172.18.0.3-1528503999525
2018-06-09 02:12:48,164 INFO  [Thread-32] impl.FsDatasetImpl (FsVolumeList.java:run(404)) - Scanning block pool BP-1513679204-172.18.0.3-1528503999525 on volume /home/hadoop/hadoopdata/hdfs/datanode/current...
2018-06-09 02:12:48,173 INFO  [Thread-32] impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Time taken to scan block pool BP-1513679204-172.18.0.3-1528503999525 on /home/hadoop/hadoopdata/hdfs/datanode/current: 9ms
2018-06-09 02:12:48,173 INFO  [Thread-19] impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(435)) - Total time to scan all replicas for block pool BP-1513679204-172.18.0.3-1528503999525: 9ms
2018-06-09 02:12:48,175 INFO  [Thread-34] impl.FsDatasetImpl (FsVolumeList.java:run(193)) - Adding replicas to map for block pool BP-1513679204-172.18.0.3-1528503999525 on volume /home/hadoop/hadoopdata/hdfs/datanode/current...
2018-06-09 02:12:48,175 INFO  [Thread-34] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(753)) - Replica Cache file: /home/hadoop/hadoopdata/hdfs/datanode/current/BP-1513679204-172.18.0.3-1528503999525/current/replicas doesn't exist 
2018-06-09 02:12:48,175 INFO  [Thread-34] impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Time to add replicas to map for block pool BP-1513679204-172.18.0.3-1528503999525 on volume /home/hadoop/hadoopdata/hdfs/datanode/current: 0ms
2018-06-09 02:12:48,175 INFO  [Thread-19] impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(224)) - Total time to add all replicas to map: 1ms
2018-06-09 02:12:48,176 INFO  [VolumeScannerThread(/home/hadoop/hadoopdata/hdfs/datanode)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(387)) - Now scanning bpid BP-1513679204-172.18.0.3-1528503999525 on volume /home/hadoop/hadoopdata/hdfs/datanode
2018-06-09 02:12:48,177 INFO  [VolumeScannerThread(/home/hadoop/hadoopdata/hdfs/datanode)] datanode.VolumeScanner (VolumeScanner.java:runLoop(545)) - VolumeScanner(/home/hadoop/hadoopdata/hdfs/datanode, DS-b3ff0b9c-a1d0-4c0d-8637-0c4e8c6e9b7d): finished scanning block pool BP-1513679204-172.18.0.3-1528503999525
2018-06-09 02:12:48,180 INFO  [Thread-19] datanode.DirectoryScanner (DirectoryScanner.java:start(475)) - Periodic Directory Tree Verification scan starting at 6/9/18 2:33 AM with interval of 21600000ms
2018-06-09 02:12:48,182 INFO  [BP-1513679204-172.18.0.3-1528503999525 heartbeating to master/172.18.0.3:9000] datanode.DataNode (BPServiceActor.java:register(763)) - Block pool BP-1513679204-172.18.0.3-1528503999525 (Datanode Uuid cb2929c8-f03f-4732-973a-dcb27b4b7fed) service to master/172.18.0.3:9000 beginning handshake with NN
2018-06-09 02:12:48,193 INFO  [VolumeScannerThread(/home/hadoop/hadoopdata/hdfs/datanode)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(404)) - VolumeScanner(/home/hadoop/hadoopdata/hdfs/datanode, DS-b3ff0b9c-a1d0-4c0d-8637-0c4e8c6e9b7d): no suitable block pools found to scan.  Waiting 1814399983 ms.
2018-06-09 02:12:48,224 INFO  [BP-1513679204-172.18.0.3-1528503999525 heartbeating to master/172.18.0.3:9000] datanode.DataNode (BPServiceActor.java:register(782)) - Block pool Block pool BP-1513679204-172.18.0.3-1528503999525 (Datanode Uuid cb2929c8-f03f-4732-973a-dcb27b4b7fed) service to master/172.18.0.3:9000 successfully registered with NN
2018-06-09 02:12:48,224 INFO  [BP-1513679204-172.18.0.3-1528503999525 heartbeating to master/172.18.0.3:9000] datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode master/172.18.0.3:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2018-06-09 02:12:48,299 INFO  [BP-1513679204-172.18.0.3-1528503999525 heartbeating to master/172.18.0.3:9000] datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x9954b8ea99dbea2f,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 30 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2018-06-09 02:12:48,299 INFO  [BP-1513679204-172.18.0.3-1528503999525 heartbeating to master/172.18.0.3:9000] datanode.DataNode (BPOfferService.java:processCommandFromActive(757)) - Got finalize command for block pool BP-1513679204-172.18.0.3-1528503999525
2018-06-09 02:33:44,184 INFO  [java.util.concurrent.ThreadPoolExecutor$Worker@38a74edc[State = -1, empty queue]] datanode.DirectoryScanner (DirectoryScanner.java:scan(665)) - BlockPool BP-1513679204-172.18.0.3-1528503999525 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2018-06-09 03:17:39,350 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_614966581_1 at /172.18.0.5:40924 [Receiving block BP-1513679204-172.18.0.3-1528503999525:blk_1073741826_1002]] datanode.DataNode (DataXceiver.java:writeBlock(717)) - Receiving BP-1513679204-172.18.0.3-1528503999525:blk_1073741826_1002 src: /172.18.0.5:40924 dest: /172.18.0.2:50010
2018-06-09 03:17:39,375 INFO  [PacketResponder: BP-1513679204-172.18.0.3-1528503999525:blk_1073741826_1002, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1530)) - src: /172.18.0.5:40924, dest: /172.18.0.2:50010, bytes: 5500, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_614966581_1, offset: 0, srvID: cb2929c8-f03f-4732-973a-dcb27b4b7fed, blockid: BP-1513679204-172.18.0.3-1528503999525:blk_1073741826_1002, duration(ns): 10976962
2018-06-09 03:17:39,375 INFO  [PacketResponder: BP-1513679204-172.18.0.3-1528503999525:blk_1073741826_1002, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1503)) - PacketResponder: BP-1513679204-172.18.0.3-1528503999525:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2018-06-09 03:23:18,424 INFO  [BP-1513679204-172.18.0.3-1528503999525 heartbeating to master/172.18.0.3:9000] datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x9954b8ea99dbea30,  containing 1 storage report(s), of which we sent 1. The reports had 1 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2018-06-09 03:23:18,424 INFO  [BP-1513679204-172.18.0.3-1528503999525 heartbeating to master/172.18.0.3:9000] datanode.DataNode (BPOfferService.java:processCommandFromActive(757)) - Got finalize command for block pool BP-1513679204-172.18.0.3-1528503999525
2018-06-09 08:33:44,183 INFO  [java.util.concurrent.ThreadPoolExecutor$Worker@38a74edc[State = -1, empty queue]] datanode.DirectoryScanner (DirectoryScanner.java:scan(665)) - BlockPool BP-1513679204-172.18.0.3-1528503999525 Total blocks: 1, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2018-06-09 09:23:19,281 INFO  [BP-1513679204-172.18.0.3-1528503999525 heartbeating to master/172.18.0.3:9000] datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x9954b8ea99dbea31,  containing 1 storage report(s), of which we sent 1. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2018-06-09 09:23:19,282 INFO  [BP-1513679204-172.18.0.3-1528503999525 heartbeating to master/172.18.0.3:9000] datanode.DataNode (BPOfferService.java:processCommandFromActive(757)) - Got finalize command for block pool BP-1513679204-172.18.0.3-1528503999525
2018-06-09 14:33:44,182 INFO  [java.util.concurrent.ThreadPoolExecutor$Worker@38a74edc[State = -1, empty queue]] datanode.DirectoryScanner (DirectoryScanner.java:scan(665)) - BlockPool BP-1513679204-172.18.0.3-1528503999525 Total blocks: 1, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2018-06-09 15:23:17,231 INFO  [BP-1513679204-172.18.0.3-1528503999525 heartbeating to master/172.18.0.3:9000] datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x9954b8ea99dbea32,  containing 1 storage report(s), of which we sent 1. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2018-06-09 15:23:17,232 INFO  [BP-1513679204-172.18.0.3-1528503999525 heartbeating to master/172.18.0.3:9000] datanode.DataNode (BPOfferService.java:processCommandFromActive(757)) - Got finalize command for block pool BP-1513679204-172.18.0.3-1528503999525
2018-06-09 20:33:44,182 INFO  [java.util.concurrent.ThreadPoolExecutor$Worker@38a74edc[State = -1, empty queue]] datanode.DirectoryScanner (DirectoryScanner.java:scan(665)) - BlockPool BP-1513679204-172.18.0.3-1528503999525 Total blocks: 1, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2018-06-09 20:40:06,034 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-469333125_1 at /172.18.0.5:43220 [Receiving block BP-1513679204-172.18.0.3-1528503999525:blk_1073741829_1005]] datanode.DataNode (DataXceiver.java:writeBlock(717)) - Receiving BP-1513679204-172.18.0.3-1528503999525:blk_1073741829_1005 src: /172.18.0.5:43220 dest: /172.18.0.2:50010
2018-06-09 20:40:06,042 INFO  [PacketResponder: BP-1513679204-172.18.0.3-1528503999525:blk_1073741829_1005, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1530)) - src: /172.18.0.5:43220, dest: /172.18.0.2:50010, bytes: 28787, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-469333125_1, offset: 0, srvID: cb2929c8-f03f-4732-973a-dcb27b4b7fed, blockid: BP-1513679204-172.18.0.3-1528503999525:blk_1073741829_1005, duration(ns): 6888904
2018-06-09 20:40:06,042 INFO  [PacketResponder: BP-1513679204-172.18.0.3-1528503999525:blk_1073741829_1005, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1503)) - PacketResponder: BP-1513679204-172.18.0.3-1528503999525:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2018-06-09 20:40:06,060 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-469333125_1 at /172.18.0.5:43222 [Receiving block BP-1513679204-172.18.0.3-1528503999525:blk_1073741830_1006]] datanode.DataNode (DataXceiver.java:writeBlock(717)) - Receiving BP-1513679204-172.18.0.3-1528503999525:blk_1073741830_1006 src: /172.18.0.5:43222 dest: /172.18.0.2:50010
2018-06-09 20:40:06,062 INFO  [PacketResponder: BP-1513679204-172.18.0.3-1528503999525:blk_1073741830_1006, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1530)) - src: /172.18.0.5:43222, dest: /172.18.0.2:50010, bytes: 2, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-469333125_1, offset: 0, srvID: cb2929c8-f03f-4732-973a-dcb27b4b7fed, blockid: BP-1513679204-172.18.0.3-1528503999525:blk_1073741830_1006, duration(ns): 954989
2018-06-09 20:40:06,062 INFO  [PacketResponder: BP-1513679204-172.18.0.3-1528503999525:blk_1073741830_1006, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1503)) - PacketResponder: BP-1513679204-172.18.0.3-1528503999525:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2018-06-09 20:47:39,133 INFO  [BP-1513679204-172.18.0.3-1528503999525 heartbeating to master/172.18.0.3:9000] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(217)) - Scheduling blk_1073741829_1005 file /home/hadoop/hadoopdata/hdfs/datanode/current/BP-1513679204-172.18.0.3-1528503999525/current/finalized/subdir0/subdir0/blk_1073741829 for deletion
2018-06-09 20:47:39,134 INFO  [BP-1513679204-172.18.0.3-1528503999525 heartbeating to master/172.18.0.3:9000] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(217)) - Scheduling blk_1073741830_1006 file /home/hadoop/hadoopdata/hdfs/datanode/current/BP-1513679204-172.18.0.3-1528503999525/current/finalized/subdir0/subdir0/blk_1073741830 for deletion
2018-06-09 20:47:39,135 INFO  [Async disk worker #0 for volume /home/hadoop/hadoopdata/hdfs/datanode/current] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(321)) - Deleted BP-1513679204-172.18.0.3-1528503999525 blk_1073741829_1005 file /home/hadoop/hadoopdata/hdfs/datanode/current/BP-1513679204-172.18.0.3-1528503999525/current/finalized/subdir0/subdir0/blk_1073741829
2018-06-09 20:47:39,135 INFO  [Async disk worker #0 for volume /home/hadoop/hadoopdata/hdfs/datanode/current] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(321)) - Deleted BP-1513679204-172.18.0.3-1528503999525 blk_1073741830_1006 file /home/hadoop/hadoopdata/hdfs/datanode/current/BP-1513679204-172.18.0.3-1528503999525/current/finalized/subdir0/subdir0/blk_1073741830
2018-06-09 21:23:18,223 INFO  [BP-1513679204-172.18.0.3-1528503999525 heartbeating to master/172.18.0.3:9000] datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x9954b8ea99dbea33,  containing 1 storage report(s), of which we sent 1. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2018-06-09 21:23:18,224 INFO  [BP-1513679204-172.18.0.3-1528503999525 heartbeating to master/172.18.0.3:9000] datanode.DataNode (BPOfferService.java:processCommandFromActive(757)) - Got finalize command for block pool BP-1513679204-172.18.0.3-1528503999525
2018-06-10 02:33:44,182 INFO  [java.util.concurrent.ThreadPoolExecutor$Worker@38a74edc[State = -1, empty queue]] datanode.DirectoryScanner (DirectoryScanner.java:scan(665)) - BlockPool BP-1513679204-172.18.0.3-1528503999525 Total blocks: 1, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2018-06-10 03:23:19,228 INFO  [BP-1513679204-172.18.0.3-1528503999525 heartbeating to master/172.18.0.3:9000] datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x9954b8ea99dbea34,  containing 1 storage report(s), of which we sent 1. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2018-06-10 03:23:19,231 INFO  [BP-1513679204-172.18.0.3-1528503999525 heartbeating to master/172.18.0.3:9000] datanode.DataNode (BPOfferService.java:processCommandFromActive(757)) - Got finalize command for block pool BP-1513679204-172.18.0.3-1528503999525
2018-06-10 06:52:52,797 WARN  [BP-1513679204-172.18.0.3-1528503999525 heartbeating to master/172.18.0.3:9000] datanode.DataNode (BPServiceActor.java:offerService(727)) - IOException in offerService
java.io.EOFException: End of File Exception between local host is: "slave1/172.18.0.2"; destination host is: "master":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:788)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:514)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:645)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:841)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1798)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1167)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1063)
